instructions.md
本ドキュメントは、生成AIによる自律的なテスト駆動開発を行うための包括的な手順と推奨事項をまとめたものです。
週に一回、ウェブサイト・APIから取得したプロンプトエンジニアの求人情報をデータベースに保存し、Slackに送信するシステムを例にしていますが、他の類似プロジェクトでも活用できる設計指針となっています。

AI開発原則（必ず満たすべき5点）
常にテストファーストでAIに開発させる。
関数は小さく、マイクロサービスの原則に従って設計させる。
こまめなコミットで変更履歴が追跡可能になるようにする。
AIに問題を小さく分割して段階的に解決させる。
AIが混乱した場合は、コンテキストをリセットして再アプローチする。
1. テスト駆動開発フレームワーク
Python + Pytest をベースに採用し、GitHub Actions 上で自動テストを実行。
テストコードの作成時は、以下の手順をAIに提示する：
「この機能に必要なテスト項目を洗い出して、Pytestテストコードを生成してください」
「生成されたテストコードをレビューして、必要な修正を行ってください」
「テストに通るための実装コードを作成してください」
テスト → 実装 → 検証のサイクルを自動化するため、GitHub Actions のワークフローに下記を設定する：
ブランチへのプッシュ or プルリクエスト作成 → Pytest 実行 → カバレッジ計測 → 結果をSlack通知 or GitHub上に表示。
テスト失敗時のAI自己診断：
GitHub Actions がテスト結果をAIにフィードバックする仕組みを考慮し、失敗したテストケースに応じた修正差分を生成させる。
人間のレビューを必ず経て、誤った修正が連鎖しないようにする。
2. マイクロサービス/関数単位の段階的実装
2.1 システム機能分割
Fetch モジュール
ウェブサイトのスクレイピング または API コールによって、プロンプトエンジニア求人情報を取得。
主な関数:
fetch_jobs_from_api(url: str) -> list[dict]
Store モジュール
データベース（SQLiteなど）への求人情報の保存・読み出し機能を提供。
主な関数:
store_jobs_in_db(jobs: list[dict]) -> None
get_stored_jobs() -> list[dict]
Notify モジュール
Slack App + Webhook 等を利用して、新着求人情報を通知。
主な関数:
post_jobs_to_slack(jobs: list[dict], webhook_url: str) -> bool
Scheduler モジュール
週一回の実行スケジュールを管理。GitHub Actions の Scheduled Triggers や cron を想定。
シナリオ:
fetch_jobs_from_api → store_jobs_in_db → post_jobs_to_slack
2.2 段階的統合テスト
モジュール単体テスト → モジュール間の結合テスト → システム統合テスト の順で進める。
各フェーズでAIが担当するタスクを明確化し、マイルストーンを設定する：
M1: Fetch モジュール単体テスト完了
M2: Store モジュール単体テスト完了
M3: Notify モジュール単体テスト完了
M4: 3つを連携したシナリオテスト（統合テスト）完了
3. バージョン管理の自動化
3.1 コミット生成ルール
AIがコード生成した場合でも、1つの機能/修正につき1コミットを原則とする。
改修の内容が多岐にわたる場合はコミットを分割することを指示する。
3.2 コミットメッセージ規約
“feat: ”：新機能追加
“fix: ”：バグ修正
“test: ”：テストコードの追加・変更
“docs: ”：ドキュメント修正
“refactor: ”：リファクタリング
3.3 ブランチ戦略と自動マージ基準
メインブランチ（main）: 安定稼働用
開発ブランチ（develop）: 新機能の統合テストやリリース前検証
機能ブランチ（feature/xxx）: 個別の機能開発に使用
テストに合格 && レビューがOK → 開発ブランチに自動マージ。定期的にmainへリリース。
3.4 ロールバック手順
タグやリリースを打ち、メジャー・マイナー・パッチバージョン管理を行う。
重大な不具合発生時は直近の安定タグ(Release)に戻すスクリプトを用意する。
4. AIプロンプト最適化と連鎖的思考
4.1 AIプロンプトテンプレート
「モジュール名: … / 必要ライブラリ: … / 入力データと出力データの形式: … を想定したPytestコードを作成してください。」
出力形式を指定し、error handling まで考慮させる。
4.2 連鎖的思考の促し方 (Chain of Thought)
シンプルなタスクから段階を踏んで複雑化させる。
エラーや疑問があれば、AIに対して都度「このエラーの原因を分析し、修正策を提案してください」と尋ねる。
4.3 コンテキスト管理・情報整理
AIとの会話履歴が混乱したと感じた場合は、一度要点のみを整理した箇条書きを示し、改めて指示を出す。
「現在のステータス：Fetch モジュールの単体テスト中」などを定期的にリマインド。
4.4 エラー発生時のトラブルシューティングプロンプト
エラー内容をコピーし、「このエラーの原因を推定し、どのように修正するか提案してください」と具体的に依頼する。
AIの提案を確認し、必要があれば再度修正案を要求する。
5. AIツール間の連携方法
例: ChatGPT → Claude → Cursor の連携フロー
ChatGPT で最初の設計方針とテストコードの大枠を生成
Claude で詳細仕様や特殊なエッジケースを補足
Cursor（VSCode拡張など）で実際のコードを扱いながらペアプロのように修正
各ツールの得意分野を生かしつつ、共通で使うコンテキスト（前のやりとりの要約）を都度引き継ぐ。
6. 開発行き詰まり時のリセット・再構築戦略
どうしてもAIが堂々巡りをしてしまう場合：
現状の要点と問題点を整理。
会話履歴をリセット／新しいセッションを開始。
1の要点だけまとめてAIに与え、改めて「最初から手順を再度提示してほしい」と指示する。
ロールバックを行い、テストが通っていた時点に戻るという実装上のリセット方法も検討する。
7. プロジェクト全体の進捗モニタリング方法
GitHub Projects や Issues を利用し、機能ごと・モジュールごとの進捗を管理。
「完了済み」「レビュー待ち」「テスト実施中」等のステータスを看板形式で可視化。
GitHub Actions の定期レポート機能を使って、テスト通過率やコミット数などの進捗指標をSlackに通知。